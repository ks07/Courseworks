\documentclass[paper=a4, fontsize=12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{listings}
\usepackage{color}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=Python,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}

% Redefine (sub-)subsection numbering to match the assignment
\renewcommand{\thesubsection}{\thesection.\roman{subsection}}
\renewcommand{\thesubsubsection}{\thesubsection.\alph{subsubsection}}

\begin{document}

% Force to question 3
\setcounter{section}{2}
\section{Question 3}

\subsection{1-Dimension}

The approach to performing 1D range counting is very similar to the 1D range
searching problem as detailed in the lecture slides, week 11. The algorithm
requires sorting the input set \(S\) into an array, thus occupying \(O(n)\)
space and taking \(O(n \log n)\) preprocessing time. This sort could be
performed using HeapSort, which is \(O(n \log n)\) - no further preprocessing
is required. Performing count queries on this structure is then a simple matter
of performing binary search twice upon the array, once to find the
successor\footnote{The successor of a value \(x\) in a set \(S\) is the
  smallest \(x_s \in S\) such that \(x_s \geq x\). Similarly, the predecessor
  of \(x\) in \(S\) is the smallest \(x_p \in S\) such that \(x_p \geq x\).} of
\(x_1\), and again to find the predecessor\footnotemark[\value{footnote}] of
\(x_2\). Binary search is in \(O(\log n)\), thus performing it twice gives us
\(O(2 \log n)\), that is equivalent to \(O(\log n)\). The final step is a
simple \(O(1)\) subtraction operation on the indices returned from binary
search, giving the count of elements in the range \(x_1 \leq x \leq x_2\). The
following pseudocode outlines this algorithm.

\begin{lstlisting}
# Receive as input a set S of n 1D points, and two bounds X1 and X2

# Sort the input set using an O(n log n) algorithm
Sorted = NlogNSort(S)

# Use binary search to find the index of the successor of X1 (O(log n))
SuccessorX1 = SuccBinarySearch(Sorted, X1)
# Use binary search again to find index of the predecessor of X2 (O(log n))
PredecessorX2 = PredBinarySearch(Sorted, X2)

# Take the difference of the two returned indices (O(1))
Count = PredecessorX2 - SuccessorX1

# Count should now hold the 
return Count
\end{lstlisting}

As previously mentioned, in the above pseudocode the sorting step could be
implemented using HeapSort. The two functions SuccBinarySearch and
PredBinarySearch find the index\footnote{Note that the definition of successor
  and predecessor have been altered slightly here, to account for the corner
  case where the value being searched for is greater than the largest element
  of \(S\). In this case, the index returned should be \(\|S\|\), presuming a
  0-based indexing system.} of the successor and predecessor of a given value
in the supplied sorted array, respectively. In the Python programming language,
the bisect module provides implementations of binary search that can be used to
perform these operations.

\subsubsection{Correctness}

The correctness of this algorithm hinges on the sorted array that is searched
within. By definition, SuccBinarySearch finds the value of \(i_s\), given some
\(x_1\), such that \(\forall x_i \in Sorted, i < i_s : x_i < x_1\). Similarly,
PredBinarySearch finds the value of \(i_p\), given some \(x_2\), such that
\(\forall x_i \in Sorted, i \geq i_p : x_i > x_2\). Of course, as a sorted
array, it holds that \(\forall x_i, x_{i+1} \in Sorted : x_i \leq
x_{i+1}\). Combining these three properties, it holds that \(\forall i \in
\mathbb{N}_0, i \geq i_s, i < i_p : x_1 \leq Sorted_i \leq x_2\).

\section{Question 4}

\subsection{6 Approximation}

A 3 approximation for this bin packing problem can be found by making use of
the FirstFitDecreasing algorithm, with the set of all gems partitioned into two
subsets. One such subset should hold only a single type of gem, whilst the
other subset should hold the remaining two types of gem. The following proofs
do not consider the effect of choosing different gem types to partition around;
in my algorithm I will simply partition the n input gems into a subset AB,
containing all gems of type A and B, and a subset C, containing all gems of
type C. The following pseudocode makes use of a FirstFitDecreasing function,
that implements the algorithm as discussed in the lecture slides. This function
takes as input a list of gems and outputs the number of sacks required.

\begin{lstlisting}
# Receive as input a list N of n gems, i.e. n = |N|

AB = []
C  = []

# Partition the gems, O(n)
for gem in N:
  if gem.type == C:
    C.append(gem)
  else:
    AB.append(gem)

s = 0

# As only two types of gem, cannot mix more than two types in a sack. O(n^2)
s = FirstFitDecreasing(AB)

# Repeat for type C, again O(n^2)
s = s + FirstFitDecreasing(C)

# s should now hold the count of bins required
return s
\end{lstlisting}

\subsubsection{Runtime Analysis}
From the lecture slides, week 13, we have that the FirstFitDecreasing algorithm
is \(O(n^2)\), from the sorting operation that needs to be performed before
assigning items to bins. As the annotated pseudocode describes, we perform an
\(O(n)\) preprocessing step whereby the gems are split into two subsets. This
is a simple loop over all elements in N; this loop is executed n times,
performing \(O(1)\) operations in the body of the loop. The algorithm then runs
the FirstFitDecreasing algorithm twice, giving a worst case runtime of \(O(2n^2
+ n)\), which is equivalent to \(O(n^2)\). By definition, this is polynomial
time.

\subsubsection{Correctness}
From the lecture slides, week 13, the FirstFitDecreasing algorithm produces
valid solutions; the algorithm operates by finding the first bin that satisfies
the equation \(t + w \leq c\), where t is the total weight of items already in
the bin, w is the weight of the item currently being considered, and c is the
capacity of each bin (c = 1.0, in this case).

The algorithm must therefore produce valid solutions for both subsets of N (AB
and C), at least in terms of sack capacity. However, the problem also specifies
a restriction on the mixing of gem types; no sack may contain a gem of type A,
a gem of type B, and a gem of type C. This algorithm avoids violating this
condition by partitioning the gems such that the FirstFitDecreasing algorithm
is never supplied with gems of all three types at once, so it cannot produce an
invalid packing. The algorithm combines the two packings (of AB and of C), by
simply concatenating the two; or in this case, by summing the outputs of
FirstFitDecreasing. In other words, the number of sacks needed for all gems of
type A and B is found, then the number for type C is found, and the final
solution keeps type C completely separated from the others.

\subsubsection{Approximation Factor}
From the lecture slides, week 13, we are shown that the FirstFitDecreasing
algorithm produces a \(\frac{3}{2}\) approximation. \((Opt \leq s \leq
\frac{3}{2} Opt)\). Consider each subset individually; denoting the optimal
solution for the AB subset as \(Opt_{AB}\), and similarly \(Opt_C\) for the C
subset. Running FFD on these subsets will produce packings that satisfy:

\begin{alignat*}{2}
Opt_{AB}         &\leq        &s_{AB} \quad &\leq \quad \frac{3}{2} Opt_{AB}
\intertext{and}
Opt_C            &\leq        &s_C \quad    &\leq \frac{3}{2} Opt_C
\intertext{that when combined give an inequality for the overall approximation}
Opt_{AB} + Opt_C &\leq s_{AB} &+ s_C        &\leq \frac{3}{2} Opt_{AB} + \frac{3}{2} Opt_C \\
Opt_{AB} + Opt_C &\leq        &s \quad      &\leq \frac{3}{2} Opt_{AB} + \frac{3}{2} Opt_C
\end{alignat*}

In order to demonstrate the bounds of the approximation in terms of the global
optimum, \(Opt\), i.e. the optimum when considering all three types
simultaneously, it is necessary to show the relationship between the two local
optimums, \(Opt_{AB}\) and \(Opt_C\), and \(Opt\). It must be the case that
\(Opt_C \leq Opt\). This can be explained by considering that C is a subset of N,
thus by definition C must have at most n elements. Therefore, in the most
extreme case the entirety of N will in fact be gems of type C - thus the local
optimum packing for C will be equal to the global optimum for N, \(Opt\). The
only other possibility is that the subset C has fewer elements than N. Clearly
in this case, \(Opt_C \leq Opt\), as removing items from the input cannot
possibly increase the required number of bins, as all gems have positive
weights.

The same argument can be made for the subset AB, as there are no restrictions
on sacks containing only two types of gem other than the standard capacity
limit. Thus it follows that \(Opt_{AB} \leq Opt\). This can be used to express
the upper bounds of the above approximation inequality in terms of the global
optimum, like so:

\begin{alignat*}{2}
Opt_{AB} + Opt_C &\leq \quad &s \quad &\leq \frac{3}{2} Opt_{AB} + \frac{3}{2} Opt_C \\
Opt_{AB} + Opt_C &\leq \quad &s \quad &\leq \frac{3}{2} Opt + \frac{3}{2} Opt \\
Opt_{AB} + Opt_C &\leq \quad &s \quad &\leq 2 ( \frac{3}{2} Opt ) \\
Opt_{AB} + Opt_C &\leq \quad &s \quad &\leq 3 Opt
\end{alignat*}

In a similar manner, the lower bound can be simplified by observing that in the
best case, all elements of N are grouped into only one of \(Opt_{AB}\) or
\(Opt_C\). In this situation, either \(s_{AB} = 0\) or \(s_{C} = 0\) will be
true, thus \(s = s_x\). Going back to the definition of FirstFitDecreasing,
this means that the lower bound of the inequality must be \(Opt\). In any other
situation, the lower bound must be greater than or equal to \(Opt\) - this is
clear from the definition of Opt as the most efficient packing possible - it
cannot be beaten. Thus, we can simplify the entire inequality as follows:

\begin{alignat*}{2}
Opt_{AB} + Opt_C &\leq \quad &s \quad &\leq 3 Opt \\
Opt              &\leq \quad &s \quad &\leq 3 Opt
\intertext{\centering Which clearly satisfies:}
Opt              &\leq \quad &s \quad &\leq 6 Opt
\end{alignat*}

\subsection{Tighter Approximation}

A 2 approximation for the gem packing problem can be achieved by modifying the
NextFit algorithm - albeit with a constant factor on the worst case
performance, giving the inequality:

\begin{displaymath}
Opt \leq s \leq 2 Opt + 1
\end{displaymath}

This is achieved by sorting the input list, N, into type order, such that all
gems of type A are followed by those of type B, and then by type C. This sorted
input list is then fed through a modified version of the NextFit algorithm,
whereby an extra check is added to ensure that a bin holding both A and B gems
will not be considered suitable for a gem of type C. (In this case, the current
bin will move to the next, as if the capacity limit for the current bin had
been exceeded by this differently typed gem.) In the following subsections it
will be shown that this condition can only be triggered under a very specific
set of conditions, and will only result in one extra bin being added to the
output. The pseudocode below details this approach.

\begin{lstlisting}
# Receive as input a list N of n gems, i.e. n = |N|

A = []
B = []
C = []

# Partition the gems, O(n)
for gem in N:
  if gem.type == A:
    A.append(gem)
  elif gem.type == B:
    B.append(gem)
  elif gem.type == C:
    C.append(gem)

# Current sack number
s = 0
# Current sack weight total
total = 0.0
# Does current sack contain an A type gem?
hasA = False

# Concatenate lists A, B, and C (O(1))
L = A + B + C

# Loop through all gems in L, adding to the current bin until it is no longer
# possible, then moving to the next bin. (O(n))
for gem in L:
  hasA = hasA or (gem.type == A)
  total = total + gem.weight
  if (total > 1.0) or (hasA and gem.type == C):
    # The current bin is unsuitable for this gem, move to the next
    s = s + 1
    total = gem.weight
    hasA = (gem.type == A)

# Need to check if the current bin has been used.
if total > 0.0:
  s = s + 1

# s should now hold the count of bins required
return s
\end{lstlisting}

Note that this implementation will work with any chosen permutation of list
concatenation in L - e.g. \(L = C + B + A\).

\subsubsection{Runtime Analysis}
From the lecture slides, week 13, we have that the NextFit algorithm is
\(O(n)\). As the annotated pseudocode describes, we perform an \(O(n)\)
preprocessing step whereby the gems are sorted into three subsets based upon
their type. This is a simple loop over all elements in N; this loop is executed
n times, performing \(O(1)\) operations in the body of the loop. The algorithm
then runs the modified NextFit algorithm. As demonstrated in the pseduocode,
this modified NextFit loop continues to be \(O(n)\) - the only modifications
being the addition of some constant time operations to the loop body, that runs
n times. Overall this gives a worst case runtime of \(O(2n)\), which is
equivalent to \(O(n)\). By definition, this is polynomial time.

\subsubsection{Correctness}
The core bin packing loop of the algorithm shown here is very similar to the
standard NextFit algorithm described in the lecture slides, week 13. The
standard NextFit algorithm produces valid solutions; the algorithm checks that
adding an element to the current bin will not exceed it's capacity (1.0 for the
given problem). This check is still present in the modified algorithm, such
that the restriction on total bin weight will never be exceeded.

The second restriction, whereby the mixing of all three gem types may not share
a single sack, is guaranteed by a combination of the preprocessing sort by
type, and the check against adding a C type gem to a bin that holds an A type
gem. The input list, L, is iterated over in order of type. Thus once we begin
considering C type gems, there will be no more A or B type gems to be
processed. Therefore, it is sufficient to check that when adding a C type gem
that the current bin does not contain an A type gem. In this case, the same
action is taken as is used to handle an over-capacity bin - i.e. the current
bin is moved to a new bin, and the current gem is inserted into this new
bin. This ensures that all three types are never placed into the same sack.

\subsubsection{Approximation Factor}
In most cases this modified algorithm will follow the performance of the
original NextFit algorithm. From the lecture slides, week 13, we have that
NextFit finds approximations for s in the range \(Opt \leq s \leq 2 Opt\). The
only time that the algorithm presented here performs packing differently from
the original is when a C type gem is encountered and the current bin contains
at least one A type gem. Due to the sort operation performed as a preprocessing
step, there is only one situation where an A type gem may exist in the current
bucket whilst considering a C type gem. This will be the case if, and only if:

\begin{displaymath}
\exists a \in A, \exists c \in C \text{ \quad such that \quad } a.weight + \sum\nolimits_{b \in B} b.weight + c.weight \leq 1.0
\end{displaymath}

In this special case, the current bin is finished early, and a new bin is
considered. This shifting operation wastes less than one sack's worth of
capacity, thus adding a single sack onto the found packing in the worst
case. Therefore we find the approximation to be described by the following
inequality:

\begin{displaymath}
Opt \leq s \leq 2 Opt + 1
\end{displaymath}

The lower bound here can be achieved in the case where there is only a single input gem, among others. As per the definition of \(Opt\), clearly the algorithm cannot find a packing better than this limit.

\end{document}
